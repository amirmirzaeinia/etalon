\begin{figure*}[t]
  \centering
  \begin{tabular}{| l | c | c | c | c | c | c |}
    \toprule
    & Bandwidth & Reconfig. Delay & Multicast & Comm. Paradigm & Packet Switch\\
    \midrule
    MSWL & & & & &\\
    ESWL & & & & &\\
    FSO & & & & &\\
    OCS & & & & &\\
    OCS-MC & & & & &\\
    \bottomrule
  \end{tabular}
  \caption{Examination of prior work.}
  \label{tab:prior}
\end{figure*}

\newpage\phantom{t}
\newpage



\section{Background}
\label{sec:background}

\subsection{Model}
\label{sec:model}

{\bf Network Model:} We model a datacenter as a collection of racks of servers
each containing a Top-of-Rack (ToR) switch connecting the racks to one
another. For ease of modeling we abstract the network connecting ToRs into a
single logical switch, as most prior work in new PHY-layer datacenter
technologies does. Our focus is on the switch connecting ToRs, which we assume
is implemented with a next-generation datacenter technology (e.g., steerable
wireless, free space optics, etc.). We'll refer to this switch as the new
technology switch ({\bf NTS}). While this new technology provides impressive
bandwidth benefits it has many non-traditional constraints.

Communication between ToRs may be constrained based on the technology: for
example, optical circuit switching (OCS)~\cite{TODO} limits communication to a
perfect matching of senders/receivers at a given time (e.g., if A can send to B,
B can send to C, C can send to A; A can't send to C, and B can't receive from
C). These communication pairs effectively form a \emph{logical topology} over
the fully-connected physical topology. This logical topology (herein referred to
as just the ``topology'') can change in an automated fashion according to some
scheduling algorithm. However, in order to change the topology a reconfiguration
delay penalty must be paid, during which time (potentially) all links may be
unavailable. The technology may provide multicast or other network-level
primitives. Finally, many prior works advocate the use of a packet switch ({\bf
  PS}) in addition to the NTS~\cite{TODO}. As the PS can facilitate traffic
between arbitrary pairs of senders and receivers at any point in time, it is
useful for delivering traffic that is difficult to schedule over the NTS. We see
these properties of the NTS illustrated as columns in Table~\ref{tab:prior}.

%% Matt: Maybe we can use some of this from SOLSTICE?
%% In our model, each input port of the hybrid switch is simultaneously connected
%% to both the packet switch and the circuit switch. At any point in time, however,
%% at most one VOQ at each input port may be serviced by the circuit switch,
%% whereas multiple VOQs may be drained simultaneously by the packet switch. The
%% circuit switch functions as a crossbar: it can connect any input port to any
%% output port, but no output port may be connected to multiple input ports, and no
%% input port may be connected to multiple output ports (aside from their
%% connection to the packet switch) in a single configuration.

%% The circuit switch can be reconfigured with the cost of a fixed time delay
%% $\delta$ (e.g., 20 $\mu$s~\cite{reactor:nsdi14}). Some technologies allow
%% circuits that do not change during a reconfiguration to forward data during the
%% reconfiguration period. We assume a pessimistic view that all communication
%% stops during a reconfiguration, allowing our scheduler to function with a wider
%% set of technologies. The packet switch, on the other hand, can service traffic
%% at all times.

%% To ensure high circuit utilization, each circuit configuration must remain
%% active for a long period with respect to $\delta$. For example, to ensure 90\%
%% link utilization over the circuit switch, the average duration of a
%% configuration needs to be at least $9\delta$ (e.g., 180 $\mu$s) to amortize the
%% reconfiguration delay.

%% One important distinction between our model and traditional switches is that
%% there is no queueing at the output ports of the circuit switch. This restriction
%% rules out any crossbar scheduler that requires a speed-up factor. Hybrid
%% switches instead use a lower-data-rate commodity packet switch (without
%% constraints on queueing/speed-up), to make up for the reconfiguration delay and
%% any scheduling inefficiency. We will see that this addition provides an
%% improvement compared to existing approaches.

{\bf Network Scheduling:} Network scheduling is the process of deciding how to
properly map demand from sources to destinations to an ordered set of NTS
topology configurations and corresponding durations. If the technology includes
an additional packet switch the scheduler needs to determine what data should be
sent over it. Scheduling is a three-step closed-loop system: 1) demand in the
datacenter for the next epoch (e.g., 30ms~\cite{TODO}) is estimated (typically
by observing recent demand) and sent to a centralized controller, 2) an
algorithm runs at the controller to determine the schedule for the next epoch,
and 3) the schedule is disseminated to the NTS and/or ToR/hosts (depending on
implementation). Traffic estimated during step 1 is assumed to be admissible
within the next epoch or else demand could build up infinitely. A proper
examination of scheduling algorithms for specific next-generation technologies
has been looked at in prior work~\cite{solstice, eclpise} and is outside of the
scope of this work.

%% Matt: We may be able to use this stuff if we squish it down and point to that
%% it's related to solving most of these scheduling problems?
%% The crossbar switch scheduling problem has been studied for decades. The basic
%% approach, often referred to as time slot assignment (TSA), decomposes an
%% accumulated demand matrix into a set of weighted permutation matrices.
%% Classical results~\cite{bvn} and early work on scheduling satellite-switched
%% time-division multiple access (SS/TDMA) systems~\cite{inukai} show how to
%% compute a perfect schedule, but the resulting schedules consist of $O(n^2)$
%% configurations. Although this approach is optimal for a switch with trivial
%% reconfiguration time, it performs poorly in our network model.

%% On the opposite end of the spectrum, when reconfiguration time is large, there
%% exist algorithms~\cite{dally,gopal,qlef} that use the fewest possible number of
%% configurations ($n$).  For moderate reconfiguration times, DOUBLE~\cite{dally}
%% computes a schedule that requires twice the minimum number of configurations,
%% $2n$. Further improved algorithms~\cite{dcswitch,hamdi,srf} take the actual
%% reconfiguration delay into account.  These algorithms, however, do not benefit
%% from sparse demand matrices, continuing to require $O(n)$ configurations to
%% cover the demand.

%% Other existing work uses a speedup factor (i.e., the ratio of the internal
%% transfer rate to the port link rate). Perhaps the most well known example is
%% iSLIP~\cite{islip}, which requires a 2$\times$ speedup to maintain stability.
%% Many of these algorithms perform poorly (i.e., introduce large delays) when the
%% traffic demand is skewed, leading others to suggest using randomization to
%% address the issue~\cite{giaccone}.

\begin{figure*}[t]
  \centering
  \begin{tabular}{| l | c | c | c | c | c |}
    \toprule
    & MapReduce & DFS & VM Migration & Search & Combined\\
    \midrule
    MSWL & & & & &\\
    ESWL & & & & &\\
    FSO & & & & &\\
    OCS & & & & &\\
    OCS-MC & & & & &\\
    \bottomrule
  \end{tabular}
  \caption{Comparing technologies based on which workloads they excel in.}
  \label{tab:workloads-to-technologies}
\end{figure*}

\subsection{Prior Technologies}
\label{sec:prior_technologies}

\TODO{We analyze previous work within this model and summarize the results in
  Table~\ref{tab:prior}. Put more technical background in each.}

{\bf MSWL:} Mechanically-steerable Wireless (MSWL) physically move antennas to
establish high bandwidth point-to-point 60GHz wireless links between ToRs. In
prior work the line-of-sight directionality for this is facilitated through
mirrors placed on the ceiling of the datacenter~\cite{mirormiror}. The physical
movement of the antennas require long periods of reconfiguration delay
...\TODO{finish...}

{\bf ESWL:} Electronically-steerable Wireless (ESWL) use phase-array antennas to
avoid needing to physically move antennas like in MSWL. Phase-array antennas
allow ESWL to establish point-to-point high bandwidth 60GHz wireless links using
relatively simple signal processing tricks~\cite{flyways}. \TODO{finish}

{\bf FSO:} Free-space Optics (FSO) sends an optical signal through the air
rather than through fiber. This provides lower end-to-end latency than
traditional fiber, but like MSWL requires physically moving the laser to adjust
the topology, incurring higher reconfiguration delay~\cite{firefly}. \TODO{finish}

{\bf OCS:} Optical Circuit Switching (OCS) uses next-generation fiber optics to
build a reconfigurable bufferless optical switch~\cite{helios, c-through,
  mordia, reactor}. Although in can provide incredibly high bandwidth through
WDM, it is limited by it's fairly long reconfiguration delay. Communication is
limited to a perfect matching, multicast is generally not
considered~\cite{solstice}, but an additional packet switch is thoroughly
utilized. \TODO{finish}

{\bf OCS-MC:} Optical Circuit Switching with Multicast (OCS-MC) is a recent line
of work that uses \TODO{xxx} to allow for multicast/broadcast from a single
sender to multiple receivers. However, as with other technologies, a receiver
can only receive from one sender at a time, making ``incast''-style workloads as
difficult as other technologies. \TODO{finish}

%% Matt: Reuse some of this? This top para wasn't actually in SOLSTICE
%% Recent literature is replete with discussion of hybrid networks, both in terms
%% of adding optical switches~\cite{c-Through, helios:sigcomm10, mordia:hotnets12,
%%   reactor:nsdi14} or wireless links~\cite{flyways, augmenting-dc-wireless,
%%   mirror-mirror}. Some focus on general design \cite{c-Through,
%%   helios:sigcomm10} whereas others focus on the physical aspects
%% \cite{mordia:hotnets12, reactor:nsdi14}.  None, however, focus specifically on
%% the practical aspects of scheduling traffic for high network
%% utilization. Instead, recent proposals assume a scheduling oracle that can
%% compute switch configurations and map traffic to them in an optimal fashion.

%% We consider a single switch in a hybrid network fabric that consists of $n$
%% ports. In the context of datacenters, these ports would typically connect to
%% individual servers or Top-of-Rack (ToR) switches. We leave multiple-switch
%% networks to future work. Our model assumes each port is logically input
%% queued. In some realizations, the queues are located at the senders
%% themselves~\cite{reactor:nsdi14}, although alternatively, the queues could be
%% located at the ToR switches or the hybrid switch itself.

%% Our abstraction of a hybrid switch (shown on the left-hand side of
%% Figure~\ref{fig:arch}) consists of two separate switches: a circuit switch,
%% typically optical or RF, capable of forwarding at very high bandwidth, and a
%% low-bandwidth (e.g., an order of magnitude lower) packet switch. Both switches
%% source packets from the queues at each of the $n$ input ports, structured as
%% virtual output queues (VOQs). Although the circuit switch has a significantly
%% faster data rate than the packet switch, it incurs a non-trivial reconfiguration
%% penalty.

%% Prior work has focused on building such a switch~\cite{reactor:nsdi14,
%%   mordia:sigcomm13, c-Through, helios:sigcomm10}, with little focus on how to
%% schedule traffic, instead relying on an omniscient oracle to compute optimal
%% switch configurations. ReacToR, for example, leaves the selection and evaluation
%% of a hybrid scheduler as future work~\cite{reactor:nsdi14}.

\subsection{Datacenter Workloads}
\label{sec:workloads}

Here we compare a variety of common datacenter workloads and reason about how
the differing technologies impact their performance. \TODO{point more to
  specific technologies in the following paras and also point to the table.}

{\bf MapReduce:} MapReduce~\cite{MapReduce} is a staged-computation style
workload. All computation and data transfers of the current stage must complete
before the next stage can start. In the shuffle phase this typically involves
all participating nodes (potentially all nodes in the datacenter) sending some
non-trivial amount of data (e.g., 10-100MB) to all other participating
nodes. This all-to-all style communication is potentially very tricky for
networks with communication constraints as it requires each node to eventually
talk to each other node. If every node in the network \emph{must} talk to every
other node in the network and transfer an equal amount of data, then round-robin
is the optimal scheduling algorithm. \TODO{Forward pointer to anycast?}

{\bf DFS:} Distributed File Systems (e.g., NFS~\cite{NFS}, AFS~\cite{AFS}, etc.)
are a replication-style workload. Data enters the system at a single node in the
datacenter and must be replicated to some additional nodes (e.g., 3) elsewhere
in the datacenter. The entry node and replication nodes are generally assumed to
be random. Data is additionally assumed to be non-trivial in size (e.g.,
10MB). This kind of workload works especially well if the underlying technology
supports multicast (e.g., OSC-MC), but can work even better if the selection of
replication nodes can either be fixed per entry node or selected taking the
network into account.

{\bf VM Migration:} VM Migration is a bulk-data style workload. VM Migration
typical involves moving rather large (e.g., 10s of GBs) virtual machine images
from a single machine in the datacenter to another machine to facilitate load
balancing of various resources. This workload can make great use of technologies
that provide extreme bandwidth gains over traditional technologies even if their
communication constraints are rigid and they have high reconfiguration delays.

{\bf Search:} Search is an interactive-style workload. Search involves small
queries entering the datacenter at random nodes. These nodes then need to
contact multiple (e.g., 3-10) other nodes in the datacenter to form a response
to send back to the query issuer (typically a human). Search workloads require
very fast response times but involve little network utilization per query (e.g.,
10s of KBs). This workload can be difficult for technologies that are
communication constrained with long reconfiguration delays but don't have an
additional packet switch to delivery low-latency traffic.

{\bf Combined:} The combined workload effectively combines the low-latency
traffic of a search workload with the bulk data transfers of the migration
workload. This workload can be very difficult unless the underlying technology
has a way of splitting the two classes of traffic (e.g., by reserving a packet
switch for low-latency traffic).

